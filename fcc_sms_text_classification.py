# -*- coding: utf-8 -*-
"""fcc_sms_text_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q1lw7HPVrXmtgwyFvgUnexvyOz0bN8Oh
"""

!pip install keras_cv
!pip install --upgrade tensorflow
import tensorflow as tf
from tensorflow import keras
import pandas as pd
import numpy as np
from keras import layers

# get data 
!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv
!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv

train_file_path = "train-data.tsv"
test_file_path = "valid-data.tsv"

df_train = pd.read_csv(train_file_path, sep='\t', header = 0, names = ['label', 'text'])
df_train.head()

df_valid = pd.read_csv(test_file_path, sep = '\t', header = 0, names = ['label', 'text'])
df_valid.head()

train_text = df_train.text.values
df_train.label[df_train.label == 'spam'] = 0
df_train.label[df_train.label == 'ham'] = 1
train_label = df_train.label.values
val_text = df_valid.text.values
df_valid.label[df_valid.label == 'spam'] = 0
df_valid.label[df_valid.label == 'ham'] = 1
val_label = df_valid.label.values
print(train_label, train_label.shape)

input_length = 80
al_vocab = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
alnum_vocab = ['Â£', '!', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']

from keras_preprocessing.sequence import pad_sequences
def convert_text(text, vocab):
  char2idx = {u:i for i, u in enumerate(vocab)}
  def text_to_int(text):
    arr = list()
    for i in range(len(text)):
      arr.append([char2idx[c] for c in text[i] if c in char2idx])
    return np.asarray(arr, dtype = object)
  text_as_int = text_to_int(text)
  text_as_int = pad_sequences(text_as_int, input_length)
  text_as_int = np.array([item[0:] for item in text_as_int]).astype('int64')
  dataset = text_as_int.reshape(len(text), input_length)
  dataset = tf.convert_to_tensor(dataset)
  return dataset

convert_text(train_text, al_vocab)

al_train_dataset = convert_text(train_text, al_vocab)
alnum_train_dataset = convert_text(train_text, alnum_vocab)
al_val_dataset = convert_text(val_text, al_vocab)
alnum_val_dataset = convert_text(val_text, alnum_vocab)
train_label = train_label.astype('int64')
train_label = train_label.reshape(len(train_label), 1)
train_label = tf.convert_to_tensor(train_label)
val_label = val_label.astype('int64')
val_label = val_label.reshape(len(val_label), 1)
val_label = tf.convert_to_tensor(val_label)

al_model = keras.Sequential([
    layers.Embedding(input_dim = len(al_vocab)+1, output_dim = 64, input_length = input_length, mask_zero = True), 
    layers.LSTM(64, return_sequences = True),
    layers.LSTM(128, return_sequences = False),
    layers.Dense(32, activation = 'tanh'),
    layers.Dense(1, activation = 'sigmoid')
])
al_model.summary()

al_model.compile(optimizer = 'rmsprop', loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics = tf.keras.metrics.FalsePositives())
al_model.fit(al_train_dataset, train_label, batch_size = 80, epochs = 25, validation_data = (al_val_dataset, val_label))

alnum_model = keras.Sequential([
    layers.Embedding(input_dim = len(alnum_vocab)+1, output_dim = 64, input_length = input_length, mask_zero = True), 
    layers.LSTM(64, return_sequences = True),
    layers.LSTM(128, return_sequences = False),
    layers.Dense(32, activation = 'tanh'),
    layers.Dense(1, activation = 'sigmoid')
])
alnum_model.summary()

alnum_model.compile(optimizer = 'rmsprop', loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics = tf.keras.metrics.FalsePositives())
alnum_model.fit(alnum_train_dataset, train_label, batch_size = 1, epochs = 3, validation_data = (alnum_val_dataset, val_label))

def formatText(pred_text, vocab):
  char2idx = {u:i for i, u in enumerate(vocab)}
  arr = list()
  for i in range(len(pred_text)):
    arr.append([char2idx[c] for c in pred_text[i] if c in char2idx])
  arr2 = list()
  for i in range(len(arr)-1):
    if arr[i] != []:
      arr2.append(arr[i][0])
  pred_text = np.asarray(arr2).astype('int64')
  pred_text = pred_text.reshape(1, len(pred_text))
  pred_text = pad_sequences(pred_text, input_length)
  return pred_text

def predict_message(pred_text):
  
  prediction1 = al_model.predict(tf.convert_to_tensor(formatText(pred_text, al_vocab)))
  prediction2 = alnum_model.predict(tf.convert_to_tensor(formatText(pred_text, alnum_vocab)))
  prob1 = prediction1[0][0]
  prob2 = prediction2[0][0]
  print(prob1, prob2)
  probability = (prob1+prob2)/2
  if probability > 0.5:
    output = [probability, 'ham']
  else:
      output = [probability, 'spam']
  return output
