{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yeemeitsang/spam-text-classification-roberta?scriptVersionId=130286904\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Introduction**\n\nWelcome to this walkthrough on building a spam text classifier using pretrained models from Hugging Face. In this notebook, we will be using data provided by freeCodeCamp to further train a roberta-base model to differentiate between spam and non-spam texts. We will be using the Roberta Tokenizer to tokenize text messages and training the model on a GPU for faster processing.\n\nThe freeCodeCamp test suite for the [Neural Network SMS Text Classifier project](https://www.freecodecamp.org/learn/machine-learning-with-python/machine-learning-with-python-projects/neural-network-sms-text-classifier) is used as a reference for evaluating the performance of your model. You can also compose your custom messages and see how the model performs on them.\n\nNote that to successfully run this notebook, you will need access to wandb, which can be used to track your experiments and visualize your results.\n\nIf you prefer building your own models from scratch, you may find [my GitHub repository](https://github.com/a-t-em/Keras-LSTM-spam-text-classification) on spam text classification useful as a reference. The repository contains an example of a TensorFlow LSTM model using character embeddings trained on the same dataset.","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-05-20T06:44:03.132431Z","iopub.execute_input":"2023-05-20T06:44:03.132798Z","iopub.status.idle":"2023-05-20T06:44:16.274419Z","shell.execute_reply.started":"2023-05-20T06:44:03.132762Z","shell.execute_reply":"2023-05-20T06:44:16.273038Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#import libraries\nfrom transformers import pipeline\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import TextClassificationPipeline\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nimport tensorflow as tf\nfrom tensorflow import keras\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom keras import layers\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:18.456849Z","iopub.execute_input":"2023-05-20T10:20:18.457414Z","iopub.status.idle":"2023-05-20T10:20:18.470708Z","shell.execute_reply.started":"2023-05-20T10:20:18.457372Z","shell.execute_reply":"2023-05-20T10:20:18.46704Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"**Load data and prepare training and validation datasets**","metadata":{}},{"cell_type":"code","source":"# get data from freeCodeCamp\n!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n\ntrain_file_path = \"train-data.tsv\"\ntest_file_path = \"valid-data.tsv\"","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:20.661826Z","iopub.execute_input":"2023-05-20T10:20:20.662277Z","iopub.status.idle":"2023-05-20T10:20:24.160581Z","shell.execute_reply.started":"2023-05-20T10:20:20.662242Z","shell.execute_reply":"2023-05-20T10:20:24.158842Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n--2023-05-20 10:20:21--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\nResolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.2.33, 104.26.3.33, ...\nConnecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 358233 (350K) [text/tab-separated-values]\nSaving to: ‘train-data.tsv.1’\n\ntrain-data.tsv.1    100%[===================>] 349.84K  --.-KB/s    in 0.02s   \n\n2023-05-20 10:20:22 (21.9 MB/s) - ‘train-data.tsv.1’ saved [358233/358233]\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n--2023-05-20 10:20:23--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\nResolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 172.67.70.149, 104.26.2.33, ...\nConnecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 118774 (116K) [text/tab-separated-values]\nSaving to: ‘valid-data.tsv.1’\n\nvalid-data.tsv.1    100%[===================>] 115.99K  --.-KB/s    in 0.005s  \n\n2023-05-20 10:20:24 (21.1 MB/s) - ‘valid-data.tsv.1’ saved [118774/118774]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#load and view train data\ndf_train = pd.read_csv(train_file_path, sep='\\t', header = 0, names = ['label', 'text'])\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:29.704078Z","iopub.execute_input":"2023-05-20T10:20:29.705044Z","iopub.status.idle":"2023-05-20T10:20:29.749968Z","shell.execute_reply.started":"2023-05-20T10:20:29.704989Z","shell.execute_reply":"2023-05-20T10:20:29.748577Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"  label                                               text\n0   ham                           you can never do nothing\n1   ham  now u sound like manky scouse boy steve,like! ...\n2   ham  mum say we wan to go then go... then she can s...\n3   ham  never y lei... i v lazy... got wat? dat day ü ...\n4   ham  in xam hall boy asked girl tell me the startin...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>you can never do nothing</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>now u sound like manky scouse boy steve,like! ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>mum say we wan to go then go... then she can s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>in xam hall boy asked girl tell me the startin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#load and view validation data\ndf_valid = pd.read_csv(test_file_path, sep = '\\t', header = 0, names = ['label', 'text'])\ndf_valid.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:31.93021Z","iopub.execute_input":"2023-05-20T10:20:31.930672Z","iopub.status.idle":"2023-05-20T10:20:31.965193Z","shell.execute_reply.started":"2023-05-20T10:20:31.930635Z","shell.execute_reply":"2023-05-20T10:20:31.963605Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"  label                                               text\n0   ham         not much, just some textin'. how bout you?\n1   ham  i probably won't eat at all today. i think i'm...\n2   ham  don‘t give a flying monkeys wot they think and...\n3   ham                                who are you seeing?\n4   ham  your opinion about me? 1. over 2. jada 3. kusr...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>not much, just some textin'. how bout you?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>i probably won't eat at all today. i think i'm...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>don‘t give a flying monkeys wot they think and...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>who are you seeing?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>your opinion about me? 1. over 2. jada 3. kusr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#prepare train data\ntrain_text = df_train.text.values\ndf_train.label[df_train.label == 'spam'] = 1\ndf_train.label[df_train.label == 'ham'] = 0\ntrain_label = df_train.label.values\ntrain_text, train_label","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:34.268699Z","iopub.execute_input":"2023-05-20T10:20:34.270388Z","iopub.status.idle":"2023-05-20T10:20:34.30183Z","shell.execute_reply.started":"2023-05-20T10:20:34.270335Z","shell.execute_reply":"2023-05-20T10:20:34.299991Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"(array(['you can never do nothing',\n        'now u sound like manky scouse boy steve,like! i is travelling on da bus home.wot has u inmind 4 recreation dis eve?',\n        'mum say we wan to go then go... then she can shun bian watch da glass exhibition...',\n        ...,\n        'free entry into our £250 weekly competition just text the word win to 80086 now. 18 t&c www.txttowin.co.uk',\n        '-pls stop bootydelious (32/f) is inviting you to be her friend. reply yes-434 or no-434 see her: www.sms.ac/u/bootydelious stop? send stop frnd to 62468',\n        \"tell my  bad character which u dnt lik in me. i'll try to change in  &lt;#&gt; . i ll add tat 2 my new year resolution. waiting for ur reply.be frank...good morning.\"],\n       dtype=object),\n array([0, 0, 0, ..., 1, 1, 0], dtype=object))"},"metadata":{}}]},{"cell_type":"code","source":"#prepare validation data\nval_text = df_valid.text.values\ndf_valid.label[df_valid.label == 'spam'] = 1\ndf_valid.label[df_valid.label == 'ham'] = 0\nval_label = df_valid.label.values\nval_text, val_label","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:36.59665Z","iopub.execute_input":"2023-05-20T10:20:36.598813Z","iopub.status.idle":"2023-05-20T10:20:36.650231Z","shell.execute_reply.started":"2023-05-20T10:20:36.598705Z","shell.execute_reply":"2023-05-20T10:20:36.648872Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"(array([\"not much, just some textin'. how bout you?\",\n        \"i probably won't eat at all today. i think i'm gonna pop. how was your weekend? did u miss me?\",\n        'don‘t give a flying monkeys wot they think and i certainly don‘t mind. any friend of mine and all that!',\n        ...,\n        \"where are you ? what are you doing ? are yuou working on getting the pc to your mom's ? did you find a spot that it would work ? i need you\",\n        'ur cash-balance is currently 500 pounds - to maximize ur cash-in now send cash to 86688 only 150p/msg. cc: 08708800282 hg/suite342/2lands row/w1j6hl',\n        'not heard from u4 a while. call 4 rude chat private line 01223585334 to cum. wan 2c pics of me gettin shagged then text pix to 8552. 2end send stop 8552 sam xxx'],\n       dtype=object),\n array([0, 0, 0, ..., 0, 1, 1], dtype=object))"},"metadata":{}}]},{"cell_type":"code","source":"# choose a tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# define custom dataset\nclass TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        label = self.labels[index]\n\n        encoded_text = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=100,\n            padding='max_length',\n            truncation=True,\n            return_token_type_ids=False,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        input_ids = encoded_text['input_ids'].squeeze()\n        attention_mask = encoded_text['attention_mask'].squeeze()\n        label = torch.tensor(label)\n\n        return {\n            'input_ids': input_ids.cpu(),\n            'attention_mask': attention_mask.cpu(),\n            'labels': label.cpu()\n        }\n\n# create datasets\ntrain_dataset = TextClassificationDataset(train_text, train_label, tokenizer)\neval_dataset = TextClassificationDataset(val_text, val_label, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:45.289012Z","iopub.execute_input":"2023-05-20T10:20:45.290026Z","iopub.status.idle":"2023-05-20T10:20:45.699891Z","shell.execute_reply.started":"2023-05-20T10:20:45.289926Z","shell.execute_reply":"2023-05-20T10:20:45.698388Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"**Build and train model**","metadata":{}},{"cell_type":"code","source":"# create model\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:20:52.41065Z","iopub.execute_input":"2023-05-20T10:20:52.411815Z","iopub.status.idle":"2023-05-20T10:21:00.073577Z","shell.execute_reply.started":"2023-05-20T10:20:52.41164Z","shell.execute_reply":"2023-05-20T10:21:00.071946Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"#define custom metrics for validation to avoid error\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:21:03.544264Z","iopub.execute_input":"2023-05-20T10:21:03.54493Z","iopub.status.idle":"2023-05-20T10:21:03.563894Z","shell.execute_reply.started":"2023-05-20T10:21:03.544882Z","shell.execute_reply":"2023-05-20T10:21:03.561564Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"#set training parameters\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=8,\n    warmup_steps=10,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    fp16=True,  # enable mixed precision training\n    evaluation_strategy='epoch',  # evaluate after each epoch\n    save_strategy='epoch',  # save once per epoch\n    learning_rate=5e-5,  # default learning rate for RoBERTa\n    load_best_model_at_end=True,  # load the best model at the end of training\n    metric_for_best_model='accuracy',\n    greater_is_better=True\n)\n\n# create and train the model on the GPU\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics  \n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:21:11.168907Z","iopub.execute_input":"2023-05-20T10:21:11.170226Z","iopub.status.idle":"2023-05-20T10:24:29.269268Z","shell.execute_reply.started":"2023-05-20T10:21:11.170164Z","shell.execute_reply":"2023-05-20T10:24:29.267663Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='786' max='786' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [786/786 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.053200</td>\n      <td>0.053014</td>\n      <td>0.991373</td>\n      <td>0.991398</td>\n      <td>0.991373</td>\n      <td>0.991272</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.042100</td>\n      <td>0.088807</td>\n      <td>0.981308</td>\n      <td>0.982653</td>\n      <td>0.981308</td>\n      <td>0.981667</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.047000</td>\n      <td>0.033458</td>\n      <td>0.994249</td>\n      <td>0.994232</td>\n      <td>0.994249</td>\n      <td>0.994222</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=786, training_loss=0.06010622421217936, metrics={'train_runtime': 197.8736, 'train_samples_per_second': 63.343, 'train_steps_per_second': 3.972, 'total_flos': 644108196852000.0, 'train_loss': 0.06010622421217936, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"#optional: save model \n#model.save_pretrained('./saved_model')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T09:42:14.850601Z","iopub.execute_input":"2023-05-20T09:42:14.852248Z","iopub.status.idle":"2023-05-20T09:42:16.252408Z","shell.execute_reply.started":"2023-05-20T09:42:14.852178Z","shell.execute_reply":"2023-05-20T09:42:16.250259Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#model = RobertaForSequenceClassification.from_pretrained('./saved_model')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Make predictions**","metadata":{}},{"cell_type":"code","source":"#helper function for testing\ndef predict_message(pred_text):\n    # encode the message\n    encoded_msg = tokenizer.encode_plus(\n        pred_text,\n        add_special_tokens=True,\n        max_length=100,\n        padding='max_length',\n        truncation=True,\n        return_token_type_ids=False,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    # move the input tensor onto the GPU\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    encoded_msg = {k: v.to(device) for k, v in encoded_msg.items()}\n\n    # make the prediction\n    with torch.no_grad():\n        prediction = model(encoded_msg['input_ids'], encoded_msg['attention_mask'])\n        label = prediction.logits.argmax().item()\n    if label == 1:\n        output = [label, 'spam']\n    else:\n        output = [label, 'ham']\n    return output","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:25:17.676489Z","iopub.execute_input":"2023-05-20T10:25:17.677176Z","iopub.status.idle":"2023-05-20T10:25:17.695725Z","shell.execute_reply.started":"2023-05-20T10:25:17.677126Z","shell.execute_reply":"2023-05-20T10:25:17.692925Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"#view one example\npredict_message('our new mobile video service is live. just install on your phone to start watching.')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:25:34.646348Z","iopub.execute_input":"2023-05-20T10:25:34.646873Z","iopub.status.idle":"2023-05-20T10:25:34.689408Z","shell.execute_reply.started":"2023-05-20T10:25:34.646832Z","shell.execute_reply":"2023-05-20T10:25:34.687894Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"[1, 'spam']"},"metadata":{}}]},{"cell_type":"code","source":"#the freeCodeCamp test suite\ndef test_predictions():\n  test_messages = [\"how are you doing today\",\n                   \"sale today! to stop texts call 98912460324\",\n                   \"i dont want to go. can we try it a different day? available sat\",\n                   \"our new mobile video service is live. just install on your phone to start watching.\",\n                   \"you have won £1000 cash! call to claim your prize.\",\n                   \"i'll bring it tomorrow. don't forget the milk.\",\n                   \"wow, is your arm alright. that happened to me one time too\"\n                  ]\n\n  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n  passed = True\n\n  for msg, ans in zip(test_messages, test_answers):\n    prediction = predict_message(msg)\n    print(prediction)\n    if prediction[1] != ans:\n      passed = False\n\n  if passed:\n    print(\"You passed the challenge. Great job!\")\n  else:\n    print(\"You haven't passed yet. Keep trying.\")\n\ntest_predictions()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:25:39.319024Z","iopub.execute_input":"2023-05-20T10:25:39.320151Z","iopub.status.idle":"2023-05-20T10:25:39.445595Z","shell.execute_reply.started":"2023-05-20T10:25:39.320106Z","shell.execute_reply":"2023-05-20T10:25:39.443959Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"[0, 'ham']\n[1, 'spam']\n[0, 'ham']\n[1, 'spam']\n[1, 'spam']\n[0, 'ham']\n[0, 'ham']\nYou passed the challenge. Great job!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Bonus: compare results to model without additional training**","metadata":{}},{"cell_type":"code","source":"#choose pretrained model from hugging face\nclassifier = pipeline(\"text-classification\", model=\"textattack/roberta-base-SST-2\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:26:23.000003Z","iopub.execute_input":"2023-05-20T10:26:23.000475Z","iopub.status.idle":"2023-05-20T10:26:29.471873Z","shell.execute_reply.started":"2023-05-20T10:26:23.000438Z","shell.execute_reply":"2023-05-20T10:26:29.470067Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"#helper function for testing\ndef predict_message(pred_text):\n  results = classifier(pred_text)\n  probability = results[0]['score']\n  if results[0]['label'] == 'LABEL_1':\n    output = [probability, 'ham']\n  else:\n    output = [probability, 'spam']\n  return output","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:26:40.579976Z","iopub.execute_input":"2023-05-20T10:26:40.580432Z","iopub.status.idle":"2023-05-20T10:26:40.597882Z","shell.execute_reply.started":"2023-05-20T10:26:40.580395Z","shell.execute_reply":"2023-05-20T10:26:40.595814Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"#test message\npredict_message('Congrats! You have won a trip to Italy! Click here to claim your prize.')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:27:41.142683Z","iopub.execute_input":"2023-05-20T10:27:41.143837Z","iopub.status.idle":"2023-05-20T10:27:41.302305Z","shell.execute_reply.started":"2023-05-20T10:27:41.143788Z","shell.execute_reply":"2023-05-20T10:27:41.300811Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"[0.9688261151313782, 'ham']"},"metadata":{}}]},{"cell_type":"code","source":"#the freeCodeCamp test suite\ndef test_predictions():\n  test_messages = [\"how are you doing today\",\n                   \"sale today! to stop texts call 98912460324\",\n                   \"i dont want to go. can we try it a different day? available sat\",\n                   \"our new mobile video service is live. just install on your phone to start watching.\",\n                   \"you have won £1000 cash! call to claim your prize.\",\n                   \"i'll bring it tomorrow. don't forget the milk.\",\n                   \"wow, is your arm alright. that happened to me one time too\"\n                  ]\n\n  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n  passed = True\n\n  for msg, ans in zip(test_messages, test_answers):\n    prediction = predict_message(msg)\n    print(prediction)\n    if prediction[1] != ans:\n      passed = False\n\n  if passed:\n    print(\"You passed the challenge. Great job!\")\n  else:\n    print(\"You haven't passed yet. Keep trying.\")\n\ntest_predictions()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T10:27:59.728413Z","iopub.execute_input":"2023-05-20T10:27:59.729421Z","iopub.status.idle":"2023-05-20T10:28:00.879502Z","shell.execute_reply.started":"2023-05-20T10:27:59.729364Z","shell.execute_reply":"2023-05-20T10:28:00.87801Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"[0.9967869520187378, 'ham']\n[0.8398308753967285, 'spam']\n[0.9915432929992676, 'spam']\n[0.9446273446083069, 'ham']\n[0.9607493281364441, 'ham']\n[0.8403170704841614, 'ham']\n[0.9938607215881348, 'ham']\nYou haven't passed yet. Keep trying.\n","output_type":"stream"}]}]}